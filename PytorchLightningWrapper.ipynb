{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-Directional Attention Flow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Checkpoint and Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U PyYAML\n",
    "!pip install -U h5py\n",
    "!pip install pytorch-lightning\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "pwd = os.getcwd()\n",
    "\n",
    "class Arguments():\n",
    "    data = os.path.join(pwd, 'DATA', 'train_v2.1.json')\n",
    "    exp_folder = os.path.join(pwd, 'Experimente/EarlyStoppingAdam')\n",
    "    word_rep = os.path.join(pwd, 'DATA', 'glove.840B.300d.txt')\n",
    "    #word_rep = None\n",
    "    cuda = torch.cuda.is_available()\n",
    "    use_covariance = False\n",
    "    force_restart = False\n",
    "    train_original_data = os.path.join(pwd, 'DATA', 'train_v2.1.json')\n",
    "    train_splitted_data = os.path.join(pwd, 'DATA', 'train_part.json')\n",
    "    val_data = os.path.join(pwd, 'DATA', 'dev_v2.1.json')\n",
    "    test_splitted_data = os.path.join(pwd, 'DATA', 'eval_part.json')\n",
    "    val_splitted_data = os.path.join(pwd, 'DATA', 'dev_part.json')\n",
    "    test_reference_file = os.path.join(pwd, 'DATA', 'test_reference.json')\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "if not os.path.exists(args.exp_folder):\n",
    "    os.makedirs(args.exp_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Configurations (instead of config.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config_yaml = \"\"\"\n",
    "    bidaf:\n",
    "        dropout: 0.2\n",
    "        num_highways: 2\n",
    "        num_lstm: 2\n",
    "        hidden_size: 100\n",
    "        embedding_dim: 300\n",
    "        embedding_reduce: 100\n",
    "        characters:\n",
    "            dim: 16\n",
    "            num_filters: 100\n",
    "            filter_sizes:\n",
    "                - 5\n",
    "    training:\n",
    "        lr: 0.001\n",
    "        betas:\n",
    "            - 0.9\n",
    "            - 0.999\n",
    "        eps: 0.00000001\n",
    "        weigth_decay: 0\n",
    "        epochs: 1\n",
    "        batch_size: 60\n",
    "        limit: 400\n",
    "\"\"\"\n",
    "config = yaml.load(config_yaml, Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the MSMARCO Bidaf Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(pwd,'MsmarcoQuestionAnswering','Baseline'))\n",
    "sys.path.append(os.path.join(pwd,'MsmarcoQuestionAnswering','Baseline','scripts'))\n",
    "sys.path.append(os.path.join(pwd,'MsmarcoQuestionAnswering','Evaluation'))\n",
    "\n",
    "import MsmarcoQuestionAnswering.Baseline.scripts.checkpointing as checkpointing\n",
    "import MsmarcoQuestionAnswering.Baseline.scripts.train as train_manager\n",
    "import MsmarcoQuestionAnswering.Evaluation.ms_marco_eval as eval_manager\n",
    "#import MsmarcoQuestionAnswering.Baseline.scripts.predict as predict_manager\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MsmarcoQuestionAnswering.Baseline.mrcqa as mrcqa\n",
    "import MsmarcoQuestionAnswering.Baseline.scripts.dataset as dataset\n",
    "import json as json\n",
    "import numpy as np\n",
    "from random import shuffle, randint\n",
    "\n",
    "def try_to_split_testset(percentual_size_test, reduced_whole_size_train=1,reduced_whole_size_val=1, force_renew=False):\n",
    "    if os.path.isfile(args.train_splitted_data) and os.path.isfile(args.test_splitted_data) and os.path.isfile(args.val_splitted_data) and not force_renew:\n",
    "        return;\n",
    "    else:\n",
    "        args.force_restart = True\n",
    "        with open(args.train_original_data) as f_o:\n",
    "            train_json = json.load(f_o);\n",
    "        qids = list(train_json['query_id'].keys());\n",
    "        shuffle(qids);\n",
    "        train_size = len(qids)\n",
    "        train_size = int(reduced_whole_size_train * train_size)\n",
    "        new_train_size = int((1 - percentual_size_test) * train_size)\n",
    "        new_test_size = train_size - new_train_size\n",
    "        print(\"New Train Set has {} Datapoints\".format(new_train_size))\n",
    "        print(\"New Test Set has {} Datapoints\".format(new_test_size))\n",
    "\n",
    "        \n",
    "        qids_train = qids[0:new_train_size]\n",
    "        qids_test = qids[new_train_size:train_size]\n",
    "        \n",
    "        def copy_dict_part(old_dict, qids):\n",
    "            count = 0;\n",
    "            new_dict = dict()\n",
    "            keys = old_dict.keys()\n",
    "            for qid in qids:\n",
    "                count = count + 1;\n",
    "                if count % 10000 == 0:\n",
    "                    print('Copy progress: {}'.format(count/len(qids)))\n",
    "                for key in keys:\n",
    "                    if not key in new_dict:\n",
    "                        new_dict[key] = dict()\n",
    "                    new_dict[key][qid] = train_json[key][qid]\n",
    "            return new_dict;\n",
    "        \n",
    "        print('Start creating new train set:')\n",
    "        new_train = copy_dict_part(train_json, qids_train)\n",
    "        print('Start creating new test set:')\n",
    "        new_test = copy_dict_part(train_json, qids_test)\n",
    "        \n",
    "        with open(args.train_splitted_data, 'w') as write_f:\n",
    "            write_f.write(json.dumps(new_train))\n",
    "        with open(args.test_splitted_data, 'w') as write_f:\n",
    "            write_f.write(json.dumps(new_test))\n",
    "        \n",
    "        create_reference_file(new_test, args.test_reference_file)\n",
    "            \n",
    "        with open(args.val_data) as f_o:\n",
    "            val_json = json.load(f_o);\n",
    "        qids = list(val_json['query_id'].keys())\n",
    "        shuffle(qids)\n",
    "        val_size = len(qids)\n",
    "        new_val_size = int(reduced_whole_size_val * val_size)\n",
    "        print(\"New Validation Set has {} Datapoints\".format(new_val_size))\n",
    "\n",
    "        qids_val = qids[0:new_val_size]\n",
    "        print('Start creating new val set:')\n",
    "        new_val = copy_dict_part(val_json, qids_val)\n",
    "        #with open(args.val_splitted_data, 'w') as write_f:\n",
    "        #    write_f.write(json.dumps(new_val))\n",
    "            \n",
    "def load_data(path,limit):\n",
    "    with open(path) as f_o:\n",
    "        data, _ = dataset.load_data(json.load(f_o), span_only=True, answered_only=True, loading_limit=limit)\n",
    "    return data\n",
    "\n",
    "def create_reference_file(data_obj, reference_file_path):\n",
    "        print(\"Create test reference file\")\n",
    "        with open(reference_file_path, 'w+') as write_f:\n",
    "            for qid in data_obj[\"answers\"]:\n",
    "                try:\n",
    "                    correct = {\"query_id\": str(qid)}\n",
    "                    correct[\"answers\"] = data_obj[\"answers\"][str(qid)]\n",
    "                    write_f.write(json.dumps(correct))\n",
    "                    write_f.write(\"\\n\")\n",
    "                except KeyError:\n",
    "                    print(\"Key Error: \"+str(obj[\"query_id\"]))\n",
    "        print(\"Done creating reference file\")\n",
    "\n",
    "def init_model(id_to_token, id_to_char):\n",
    "    return mrcqa.BidafModel.from_config(config['bidaf'], id_to_token, id_to_char)\n",
    "\n",
    "def reload_model(checkpoint):\n",
    "    model, id_to_token, id_to_char = mrcqa.BidafModel.from_checkpoint(config['bidaf'], checkpoint)\n",
    "    if torch.cuda.is_available() and args.cuda:\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "    return model, id_to_token, id_to_char\n",
    "\n",
    "def inverse_dict(base_dict):\n",
    "    return {tok: id_ for id_, tok in base_dict.items()}\n",
    "\n",
    "def get_loader(data, config, used_data_per_batch=1.0):\n",
    "    data = dataset.EpochGen(\n",
    "        data,\n",
    "        batch_size=config.get('training', {}).get('batch_size', 32),\n",
    "        shuffle=True,\n",
    "        used_data_per_batch=used_data_per_batch)\n",
    "    return data\n",
    "\n",
    "def get_optimizer(model, config, state):\n",
    "    \"\"\"\n",
    "    Get the optimizer\n",
    "    \"\"\"\n",
    "    parameters = filter(lambda p: p.requires_grad,\n",
    "                        model.parameters())\n",
    "    \"\"\" ADAM Optimizer\"\"\"\n",
    "    optimizer = torch.optim.Adam(\n",
    "        parameters,\n",
    "        lr=config['training'].get('lr', 0.01),\n",
    "        betas=config['training'].get('betas', (0.9, 0.999)),\n",
    "        eps=config['training'].get('eps', 1e-8),\n",
    "        weight_decay=config['training'].get('weight_decay', 0))\n",
    "    \n",
    "    \n",
    "    \"\"\" ADAGRAD Optimizer\n",
    "    optimizer = torch.optim.Adagrad(\n",
    "        parameters,\n",
    "        lr=config['training'].get('lr', 0.01),\n",
    "        weight_decay=config['training'].get('weight_decay', 0))\n",
    "    \"\"\" \n",
    "    \"\"\" ADADELTA Optimizer \n",
    "    optimizer = torch.optim.Adadelta(\n",
    "        parameters,\n",
    "        lr=0.5)\"\"\"\n",
    "    \n",
    "    if state is not None:\n",
    "        optimizer.load_state_dict(state)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "def load_pretrained_embeddings(path, model, id_to_token):\n",
    "    with open(path) as f_o:\n",
    "            pre_trained = dataset.SymbolEmbSourceText(f_o, set(tok for id_, tok in id_to_token.items() if id_ != 0))\n",
    "    mean, cov = pre_trained.get_norm_stats(args.use_covariance)\n",
    "    rng = np.random.RandomState(2)\n",
    "    oovs = dataset.SymbolEmbSourceNorm(mean, cov, rng, args.use_covariance)\n",
    "    model.embedder.embeddings[0].embeddings.weight.data = torch.from_numpy(dataset.symbol_injection(id_to_token, 0, model.embedder.embeddings[0].embeddings.weight.data.numpy(), pre_trained, oovs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_init(train_path, val_path, test_path, config, args, loading_limit=None, used_data_per_train_epoch=1.0):\n",
    "    token_to_id = {'': 0}\n",
    "    char_to_id = {'': 0}\n",
    "    print('Load Train Data [1/6]')\n",
    "    train_data = load_data(train_path,loading_limit)\n",
    "    print('Load Validation Data [1/6]')\n",
    "    val_data = load_data(val_path,loading_limit)\n",
    "    print('Load Test Data [1/6]')\n",
    "    test_data = load_data(test_path,loading_limit)\n",
    "    \n",
    "    print('Tokenize Train Data [2/6]')\n",
    "    train_data = dataset.tokenize_data(train_data, token_to_id, char_to_id)\n",
    "    print('Tokenize Validation Data [2/6]')\n",
    "    val_data = dataset.tokenize_data(val_data, token_to_id, char_to_id)\n",
    "    print('Tokenize Test Data [2/6]')\n",
    "    test_data = dataset.tokenize_data(test_data, token_to_id, char_to_id)\n",
    "    \n",
    "    train_loader = get_loader(train_data, config, used_data_per_batch=used_data_per_train_epoch)\n",
    "    val_loader = get_loader(val_data, config) #, used_data_per_batch=used_data_per_train_epoch)\n",
    "    test_loader = get_loader(test_data, config)\n",
    "\n",
    "    print('Create Inverse Dictionaries [3/6]')\n",
    "    id_to_token = inverse_dict(token_to_id)\n",
    "    id_to_char = inverse_dict(char_to_id)\n",
    "\n",
    "    print('Initiate Model [4/6]')\n",
    "    model = init_model(id_to_token, id_to_char)\n",
    "\n",
    "    if args.word_rep:\n",
    "        print('Load pre-trained embeddings [5/6]')\n",
    "        load_pretrained_embeddings(args.word_rep, model, id_to_token)\n",
    "    else:\n",
    "        print('No pre-trained embeddings given [5/6]')\n",
    "        pass  # No pretraining, just keep the random values.\n",
    "\n",
    "    if torch.cuda.is_available() and args.cuda:\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "\n",
    "    optimizer = get_optimizer(model, config, state=None)\n",
    "    print('Done init_state [6/6]')\n",
    "    return model, id_to_token, id_to_char, optimizer, train_loader, val_loader, test_loader   \n",
    "\n",
    "\n",
    "def new_reload(train_path, val_path, test_path, checkpoint, training_state, config, args,loading_limit=None, used_data_per_train_epoch=1.0):\n",
    "    print('Load Model from Checkpoint [1/5]')\n",
    "    model, id_to_token, id_to_char = reload_model(checkpoint)\n",
    "\n",
    "    optimizer = get_optimizer(model, config, training_state)\n",
    "\n",
    "    print('Create Inverse Dictionaries [2/5]')\n",
    "    token_to_id = inverse_dict(id_to_token)\n",
    "    char_to_id = inverse_dict(id_to_char)\n",
    "\n",
    "    len_tok_voc = len(token_to_id)\n",
    "    len_char_voc = len(char_to_id)\n",
    "\n",
    "    print('Load Train Data [3/5]')\n",
    "    train_data = load_data(train_path,loading_limit)\n",
    "    print('Load Validation Data [3/5]')\n",
    "    val_data = load_data(val_path,loading_limit)\n",
    "    print('Load Test Data [3/5]')\n",
    "    test_data = load_data(test_path,loading_limit)\n",
    "    \n",
    "    limit_passage = config.get('training', {}).get('limit')\n",
    "\n",
    "    print('Tokenize Train Data [4/5]')\n",
    "    train_data = dataset.tokenize_data(train_data, token_to_id, char_to_id)\n",
    "    print('Tokenize Validation Data [4/5]')\n",
    "    val_data = dataset.tokenize_data(val_data, token_to_id, char_to_id)\n",
    "    print('Tokenize Test Data [4/5]')\n",
    "    test_data = dataset.tokenize_data(test_data, token_to_id, char_to_id)\n",
    "\n",
    "    train_loader = get_loader(train_data, config, used_data_per_batch=used_data_per_train_epoch)\n",
    "    val_loader = get_loader(val_data, config) #, used_data_per_batch=used_data_per_train_epoch)\n",
    "    test_loader = get_loader(test_data, config)\n",
    "\n",
    "    assert len(token_to_id) == len_tok_voc\n",
    "    assert len(char_to_id) == len_char_voc\n",
    "\n",
    "    print('Done reload_state [5/5]')\n",
    "    return model, id_to_token, id_to_char, optimizer, train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Lightning Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Train Set has 436714 Datapoints\n",
      "New Test Set has 48524 Datapoints\n",
      "Start creating new train set:\n",
      "Copy progress: 0.022898281255009\n",
      "Copy progress: 0.045796562510018\n",
      "Copy progress: 0.06869484376502699\n",
      "Copy progress: 0.091593125020036\n",
      "Copy progress: 0.11449140627504499\n",
      "Copy progress: 0.13738968753005398\n",
      "Copy progress: 0.160287968785063\n",
      "Copy progress: 0.183186250040072\n",
      "Copy progress: 0.206084531295081\n",
      "Copy progress: 0.22898281255008998\n",
      "Copy progress: 0.251881093805099\n",
      "Copy progress: 0.27477937506010797\n",
      "Copy progress: 0.297677656315117\n",
      "Copy progress: 0.320575937570126\n",
      "Copy progress: 0.34347421882513496\n",
      "Copy progress: 0.366372500080144\n",
      "Copy progress: 0.38927078133515297\n",
      "Copy progress: 0.412169062590162\n",
      "Copy progress: 0.435067343845171\n",
      "Copy progress: 0.45796562510017996\n",
      "Copy progress: 0.480863906355189\n",
      "Copy progress: 0.503762187610198\n",
      "Copy progress: 0.526660468865207\n",
      "Copy progress: 0.5495587501202159\n",
      "Copy progress: 0.572457031375225\n",
      "Copy progress: 0.595355312630234\n",
      "Copy progress: 0.6182535938852429\n",
      "Copy progress: 0.641151875140252\n",
      "Copy progress: 0.664050156395261\n",
      "Copy progress: 0.6869484376502699\n",
      "Copy progress: 0.709846718905279\n",
      "Copy progress: 0.732745000160288\n",
      "Copy progress: 0.755643281415297\n",
      "Copy progress: 0.7785415626703059\n",
      "Copy progress: 0.801439843925315\n",
      "Copy progress: 0.824338125180324\n",
      "Copy progress: 0.8472364064353329\n",
      "Copy progress: 0.870134687690342\n",
      "Copy progress: 0.893032968945351\n",
      "Copy progress: 0.9159312502003599\n",
      "Copy progress: 0.938829531455369\n",
      "Copy progress: 0.961727812710378\n",
      "Copy progress: 0.9846260939653869\n",
      "Start creating new test set:\n",
      "Copy progress: 0.20608358750309125\n",
      "Copy progress: 0.4121671750061825\n",
      "Copy progress: 0.6182507625092738\n",
      "Copy progress: 0.824334350012365\n",
      "Create test reference file\n",
      "Done creating reference file\n",
      "New Validation Set has 10109 Datapoints\n",
      "Start creating new val set:\n",
      "Copy progress: 0.9892175289346127\n",
      "Preparing to train...\n",
      "Load Train Data [1/6]\n",
      "Start Organizing Data...\n",
      "Organizing progress: 0.0 x 10⁴\n",
      "Organizing progress: 1.0 x 10⁴\n",
      "Organizing progress: 2.0 x 10⁴\n",
      "Organizing progress: 3.0 x 10⁴\n",
      "Organizing progress: 4.0 x 10⁴\n",
      "Organizing progress: 5.0 x 10⁴\n",
      "Organizing progress: 6.0 x 10⁴\n",
      "Organizing progress: 7.0 x 10⁴\n",
      "Organizing progress: 8.0 x 10⁴\n",
      "Organizing progress: 9.0 x 10⁴\n",
      "Organizing progress: 10.0 x 10⁴\n",
      "Organizing progress: 11.0 x 10⁴\n",
      "Organizing progress: 12.0 x 10⁴\n",
      "Organizing progress: 13.0 x 10⁴\n",
      "Organizing progress: 14.0 x 10⁴\n",
      "Organizing progress: 15.0 x 10⁴\n",
      "Organizing progress: 16.0 x 10⁴\n",
      "Organizing progress: 17.0 x 10⁴\n",
      "Organizing progress: 18.0 x 10⁴\n",
      "Organizing progress: 19.0 x 10⁴\n",
      "Organizing progress: 20.0 x 10⁴\n",
      "Organizing progress: 21.0 x 10⁴\n",
      "Organizing progress: 22.0 x 10⁴\n",
      "Organizing progress: 23.0 x 10⁴\n",
      "Organizing progress: 24.0 x 10⁴\n",
      "Organizing progress: 25.0 x 10⁴\n",
      "Organizing progress: 26.0 x 10⁴\n",
      "Organizing progress: 27.0 x 10⁴\n",
      "Organizing progress: 28.0 x 10⁴\n",
      "Organizing progress: 29.0 x 10⁴\n",
      "Organizing progress: 30.0 x 10⁴\n",
      "Organizing progress: 31.0 x 10⁴\n",
      "Organizing progress: 32.0 x 10⁴\n",
      "Organizing progress: 33.0 x 10⁴\n",
      "Organizing progress: 34.0 x 10⁴\n",
      "Organizing progress: 35.0 x 10⁴\n",
      "Organizing progress: 36.0 x 10⁴\n",
      "Organizing progress: 37.0 x 10⁴\n",
      "Organizing progress: 38.0 x 10⁴\n",
      "Organizing progress: 39.0 x 10⁴\n",
      "Organizing progress: 40.0 x 10⁴\n",
      "Organizing progress: 41.0 x 10⁴\n",
      "Organizing progress: 42.0 x 10⁴\n",
      "Organizing progress: 43.0 x 10⁴\n",
      "Load Validation Data [1/6]\n",
      "Start Organizing Data...\n",
      "Organizing progress: 0.0 x 10⁴\n",
      "Organizing progress: 1.0 x 10⁴\n",
      "Load Test Data [1/6]\n",
      "Start Organizing Data...\n",
      "Organizing progress: 0.0 x 10⁴\n",
      "Organizing progress: 1.0 x 10⁴\n",
      "Organizing progress: 2.0 x 10⁴\n",
      "Organizing progress: 3.0 x 10⁴\n",
      "Organizing progress: 4.0 x 10⁴\n",
      "Tokenize Train Data [2/6]\n",
      "0.0 x 10⁴/18.9115 x 10⁴\n",
      "1.0 x 10⁴/18.9115 x 10⁴\n",
      "2.0 x 10⁴/18.9115 x 10⁴\n",
      "3.0 x 10⁴/18.9115 x 10⁴\n",
      "4.0 x 10⁴/18.9115 x 10⁴\n",
      "5.0 x 10⁴/18.9115 x 10⁴\n",
      "6.0 x 10⁴/18.9115 x 10⁴\n",
      "7.0 x 10⁴/18.9115 x 10⁴\n",
      "8.0 x 10⁴/18.9115 x 10⁴\n",
      "9.0 x 10⁴/18.9115 x 10⁴\n",
      "10.0 x 10⁴/18.9115 x 10⁴\n",
      "11.0 x 10⁴/18.9115 x 10⁴\n",
      "12.0 x 10⁴/18.9115 x 10⁴\n",
      "13.0 x 10⁴/18.9115 x 10⁴\n",
      "14.0 x 10⁴/18.9115 x 10⁴\n",
      "15.0 x 10⁴/18.9115 x 10⁴\n",
      "16.0 x 10⁴/18.9115 x 10⁴\n",
      "17.0 x 10⁴/18.9115 x 10⁴\n",
      "18.0 x 10⁴/18.9115 x 10⁴\n",
      "Tokenize Validation Data [2/6]\n",
      "0.0 x 10⁴/0.3219 x 10⁴\n",
      "Tokenize Test Data [2/6]\n",
      "0.0 x 10⁴/2.0761 x 10⁴\n",
      "1.0 x 10⁴/2.0761 x 10⁴\n",
      "2.0 x 10⁴/2.0761 x 10⁴\n",
      "Create Inverse Dictionaries [3/6]\n",
      "Initiate Model [4/6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/Development/PythonEnv/pytorch/lib/python3.8/site-packages/torch/nn/modules/rnn.py:47: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained embeddings [5/6]\n",
      "Embeddings Loaded: 0.0 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.1 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.2 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.3 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.4 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.5 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.6 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.7 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.8 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 0.9 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.0 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.1 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.2 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.3 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.4 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.5 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.6 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.7 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.8 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 1.9 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 2.0 Mio / 2.1 Mio\n",
      "Embeddings Loaded: 2.1 Mio / 2.1 Mio\n",
      "Done init_state [6/6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-95622a752d17>:19: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  checkpoint_w = h5py.File(os.path.join(args.exp_folder, 'checkpoint'))\n"
     ]
    }
   ],
   "source": [
    "PERCENTAGE_OF_DATA_TO_USE = 0.6 #(alpha)\n",
    "PERCENTUAL_SIZE_OF_TEST_SET = 0.1 #(beta) #FEST\n",
    "PERCENTAGE_OF_REDUCED_DATA_TO_USE_PER_EPOCH = 0.16666667 #(gamma)\n",
    "\n",
    "try_to_split_testset(PERCENTUAL_SIZE_OF_TEST_SET,reduced_whole_size_train=PERCENTAGE_OF_DATA_TO_USE, reduced_whole_size_val=0.1, force_renew= True); #We use 100% of the given Data. And 10% of the Training Data will be used as Test Data. True means force rewrite Datasets.\n",
    "\n",
    "checkpoint_w, training_state_w, epoch_w = train_manager.try_to_resume(\n",
    "            args.force_restart, args.exp_folder)\n",
    "\n",
    "if checkpoint_w:\n",
    "    print('Resuming training...')\n",
    "    model_w, id_to_token_w, id_to_char_w, optimizer_w, train_loader, val_loader, test_loader = new_reload(args.train_splitted_data, args.val_splitted_data, \n",
    "                                                                                                          args.test_splitted_data, checkpoint_w, \n",
    "                                                                                                          training_state_w, config, args, used_data_per_train_epoch=PERCENTAGE_OF_REDUCED_DATA_TO_USE_PER_EPOCH)\n",
    "else:\n",
    "    print('Preparing to train...')\n",
    "    model_w, id_to_token_w, id_to_char_w, optimizer_w, train_loader, val_loader, test_loader = new_init(args.train_splitted_data, args.val_splitted_data, \n",
    "                                                                                                        args.test_splitted_data,config, args, used_data_per_train_epoch=PERCENTAGE_OF_REDUCED_DATA_TO_USE_PER_EPOCH)\n",
    "    checkpoint_w = h5py.File(os.path.join(args.exp_folder, 'checkpoint'))\n",
    "    checkpointing.save_vocab(checkpoint_w, 'vocab', id_to_token_w)\n",
    "    checkpointing.save_vocab(checkpoint_w, 'c_vocab', id_to_char_w)\n",
    "\n",
    "if torch.cuda.is_available() and args.cuda:\n",
    "    train_loader.tensor_type = torch.cuda.LongTensor\n",
    "    val_loader.tensor_type = torch.cuda.LongTensor\n",
    "    test_loader.tensor_type = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast change Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_w = get_optimizer(model_w, config, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_saves = dict();\n",
    "epoch_saves['train_loss'] = []\n",
    "epoch_saves['val_loss'] = []\n",
    "epoch_saves['test_loss'] = []\n",
    "\n",
    "#Used for test evaluation\n",
    "qid2candidate = {}\n",
    "\n",
    "import re\n",
    "regex_drop_char = re.compile('[^a-z0-9\\s]+')\n",
    "regex_multi_space = re.compile('\\s+')\n",
    "\n",
    "class BidafLightningWrapper(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def setup(self,stage):\n",
    "        pass;\n",
    "            \n",
    "    def prepare_data(self):\n",
    "        pass;\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optimizer_w;\n",
    "\n",
    "    def forward(self, passage, p_lengths, question, q_lengths):\n",
    "        return model_w(passage, p_lengths, question, q_lengths)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_loader;\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return val_loader;\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return test_loader;\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        qids, passages, queries, answers, _ = batch\n",
    "        start_log_probs, end_log_probs = self(passages[:2], passages[2], queries[:2], queries[2])\n",
    "        loss = model_w.get_loss(start_log_probs, end_log_probs, answers[:, 0], answers[:, 1])\n",
    "        return {'loss': loss, 'train_loss': loss, 'log': {'train_loss': loss}}\n",
    "\n",
    "    def training_epoch_end(self, results):\n",
    "        checkpointing.checkpoint(model_w, epoch_w, optimizer_w, checkpoint_w, args.exp_folder)\n",
    "        model_w.cuda()\n",
    "        mean_loss = self.save_statistics('train',results)\n",
    "        return {'log': {'train_loss': mean_loss}}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        qids, passages, queries, answers, _ = batch\n",
    "        start_log_probs, end_log_probs = self(passages[:2], passages[2], queries[:2], queries[2])\n",
    "        loss = model_w.get_loss(start_log_probs, end_log_probs, answers[:, 0], answers[:, 1])\n",
    "        return {'val_loss': loss, 'log': {'val_loss': loss}}\n",
    "    \n",
    "    def validation_epoch_end(self, results):\n",
    "        val_loss_mean = self.save_statistics('val',results)\n",
    "        return {'val_loss': val_loss_mean}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        qids, passages, queries, answers, mappings = batch\n",
    "        start_log_probs, end_log_probs = self(passages[:2], passages[2], queries[:2], queries[2])\n",
    "        loss = model_w.get_loss(start_log_probs, end_log_probs, answers[:, 0], answers[:, 1])\n",
    "\n",
    "        predictions = model_w.get_best_span(start_log_probs, end_log_probs)\n",
    "        predictions = predictions.cpu()\n",
    "        passages = passages[0].cpu().data\n",
    "        for qid, mapping, tokens, pred in zip(qids, mappings, passages, predictions):\n",
    "            toks = tokens[pred[0]:pred[1]]\n",
    "            start = mapping[pred[0], 0]\n",
    "            end = mapping[pred[1]-1, 1]\n",
    "            toks = regex_multi_space.sub(' ', regex_drop_char.sub(' ', ' '.join(id_to_token_w[int(tok)] for tok in toks).lower())).strip()\n",
    "            if qid not in qid2candidate:\n",
    "                qid2candidate[qid] = []\n",
    "            qid2candidate[qid].append(str(toks))\n",
    "        return {'test_loss': loss}\n",
    "\n",
    "    def test_epoch_end(self, results):\n",
    "        no_ans_set = set()\n",
    "        out_dict = {}\n",
    "        \n",
    "        #print(\"\\t no answer set\")\n",
    "        for qid in qid2candidate:\n",
    "            if len(qid2candidate[qid]) < 1 or 'No Answer Present.' in qid2candidate[qid]:\n",
    "                no_ans_set.add(qid)\n",
    "        #print(\"\\t take random answer from possible ones\")\n",
    "        for qid in qid2candidate:\n",
    "            pick = randint(0,len(qid2candidate[qid])-1)\n",
    "            out_dict[qid] = [qid2candidate[qid][pick]]\n",
    "        \n",
    "        mean_test_loss = self.save_statistics('test',results)\n",
    "        test_metrics = eval_manager.compute_metrics_from_model(args.test_reference_file, out_dict, no_ans_set)\n",
    "        outputfile = os.path.join(args.exp_folder,'metrics.json')\n",
    "        with open(outputfile,'w+') as f_o:\n",
    "            f_o.write(json.dumps(test_metrics))\n",
    "        return {'log': {'test_loss': mean_test_loss}}\n",
    "\n",
    "    def save_statistics(self, phase, results):\n",
    "        key = phase + '_loss'\n",
    "        mean_loss = torch.stack([step[key] for step in results]).mean()\n",
    "        print(\"Mean {} Loss: {}\".format(phase,mean_loss))\n",
    "        #print(epoch_saves.keys())\n",
    "        epoch_saves[key].append([step[key] for step in results])\n",
    "        return mean_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start new Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 100%|██████████| 2/2 [00:00<00:00,  3.25it/s]Mean val Loss: 8.236263275146484\n",
      "Epoch 1:  91%|█████████ | 525/579 [02:53<00:17,  3.03it/s, loss=3.453, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 526/579 [02:53<00:17,  3.03it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  91%|█████████ | 527/579 [02:53<00:17,  3.04it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  91%|█████████ | 528/579 [02:53<00:16,  3.04it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  91%|█████████▏| 529/579 [02:54<00:16,  3.04it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  92%|█████████▏| 530/579 [02:54<00:16,  3.04it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  92%|█████████▏| 531/579 [02:54<00:15,  3.04it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  92%|█████████▏| 532/579 [02:54<00:15,  3.05it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  92%|█████████▏| 533/579 [02:54<00:15,  3.05it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  92%|█████████▏| 534/579 [02:55<00:14,  3.05it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  92%|█████████▏| 535/579 [02:55<00:14,  3.05it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  93%|█████████▎| 536/579 [02:55<00:14,  3.05it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  93%|█████████▎| 537/579 [02:56<00:13,  3.05it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  93%|█████████▎| 538/579 [02:56<00:13,  3.05it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  93%|█████████▎| 539/579 [02:56<00:13,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  93%|█████████▎| 540/579 [02:56<00:12,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  93%|█████████▎| 541/579 [02:56<00:12,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  94%|█████████▎| 542/579 [02:57<00:12,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  94%|█████████▍| 543/579 [02:57<00:11,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  94%|█████████▍| 544/579 [02:57<00:11,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  94%|█████████▍| 545/579 [02:57<00:11,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  94%|█████████▍| 546/579 [02:58<00:10,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  94%|█████████▍| 547/579 [02:58<00:10,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  95%|█████████▍| 548/579 [02:58<00:10,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  95%|█████████▍| 549/579 [02:59<00:09,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  95%|█████████▍| 550/579 [02:59<00:09,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  95%|█████████▌| 551/579 [02:59<00:09,  3.07it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  95%|█████████▌| 552/579 [03:00<00:08,  3.06it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  96%|█████████▌| 553/579 [03:00<00:08,  3.07it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  96%|█████████▌| 554/579 [03:00<00:08,  3.07it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  96%|█████████▌| 555/579 [03:00<00:07,  3.07it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  96%|█████████▌| 556/579 [03:01<00:07,  3.07it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  96%|█████████▌| 557/579 [03:01<00:07,  3.07it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  96%|█████████▋| 558/579 [03:01<00:06,  3.07it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  97%|█████████▋| 559/579 [03:01<00:06,  3.07it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  97%|█████████▋| 560/579 [03:02<00:06,  3.08it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  97%|█████████▋| 561/579 [03:02<00:05,  3.08it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  97%|█████████▋| 562/579 [03:02<00:05,  3.08it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  97%|█████████▋| 563/579 [03:02<00:05,  3.08it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  97%|█████████▋| 564/579 [03:02<00:04,  3.08it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  98%|█████████▊| 565/579 [03:03<00:04,  3.09it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  98%|█████████▊| 566/579 [03:03<00:04,  3.09it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  98%|█████████▊| 567/579 [03:03<00:03,  3.09it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  98%|█████████▊| 568/579 [03:03<00:03,  3.09it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  98%|█████████▊| 569/579 [03:03<00:03,  3.09it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  98%|█████████▊| 570/579 [03:04<00:02,  3.09it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  99%|█████████▊| 571/579 [03:04<00:02,  3.09it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  99%|█████████▉| 572/579 [03:04<00:02,  3.09it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  99%|█████████▉| 573/579 [03:05<00:01,  3.10it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  99%|█████████▉| 574/579 [03:05<00:01,  3.10it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  99%|█████████▉| 575/579 [03:05<00:01,  3.10it/s, loss=3.453, v_num=6]\n",
      "Epoch 1:  99%|█████████▉| 576/579 [03:05<00:00,  3.10it/s, loss=3.453, v_num=6]\n",
      "Epoch 1: 100%|█████████▉| 577/579 [03:06<00:00,  3.10it/s, loss=3.453, v_num=6]\n",
      "Epoch 1: 100%|█████████▉| 578/579 [03:06<00:00,  3.10it/s, loss=3.453, v_num=6]\n",
      "Epoch 1: 100%|██████████| 579/579 [03:06<00:00,  3.10it/s, loss=3.453, v_num=6]Mean val Loss: 3.2846949100494385\n",
      "Epoch 1: 100%|██████████| 579/579 [03:06<00:00,  3.10it/s, loss=3.453, v_num=6]\n",
      "                                                           \u001b[AMean train Loss: 4.248210430145264\n",
      "Epoch 2:  91%|█████████ | 525/579 [02:56<00:18,  2.98it/s, loss=3.116, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 526/579 [02:56<00:17,  2.98it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  91%|█████████ | 527/579 [02:56<00:17,  2.98it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  91%|█████████ | 528/579 [02:57<00:17,  2.98it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  91%|█████████▏| 529/579 [02:57<00:16,  2.98it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  92%|█████████▏| 530/579 [02:57<00:16,  2.98it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  92%|█████████▏| 531/579 [02:57<00:16,  2.99it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  92%|█████████▏| 532/579 [02:57<00:15,  2.99it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  92%|█████████▏| 533/579 [02:58<00:15,  2.99it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  92%|█████████▏| 534/579 [02:58<00:15,  2.99it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  92%|█████████▏| 535/579 [02:58<00:14,  2.99it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  93%|█████████▎| 536/579 [02:58<00:14,  3.00it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  93%|█████████▎| 537/579 [02:59<00:14,  3.00it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  93%|█████████▎| 538/579 [02:59<00:13,  3.00it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  93%|█████████▎| 539/579 [02:59<00:13,  3.00it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  93%|█████████▎| 540/579 [02:59<00:12,  3.01it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  93%|█████████▎| 541/579 [02:59<00:12,  3.01it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  94%|█████████▎| 542/579 [03:00<00:12,  3.01it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  94%|█████████▍| 543/579 [03:00<00:11,  3.01it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  94%|█████████▍| 544/579 [03:00<00:11,  3.01it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  94%|█████████▍| 545/579 [03:00<00:11,  3.01it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  94%|█████████▍| 546/579 [03:01<00:10,  3.02it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  94%|█████████▍| 547/579 [03:01<00:10,  3.02it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  95%|█████████▍| 548/579 [03:01<00:10,  3.02it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  95%|█████████▍| 549/579 [03:01<00:09,  3.02it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  95%|█████████▍| 550/579 [03:01<00:09,  3.02it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  95%|█████████▌| 551/579 [03:02<00:09,  3.02it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  95%|█████████▌| 552/579 [03:02<00:08,  3.03it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  96%|█████████▌| 553/579 [03:02<00:08,  3.03it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  96%|█████████▌| 554/579 [03:02<00:08,  3.03it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  96%|█████████▌| 555/579 [03:02<00:07,  3.03it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  96%|█████████▌| 556/579 [03:03<00:07,  3.03it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  96%|█████████▌| 557/579 [03:03<00:07,  3.04it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  96%|█████████▋| 558/579 [03:03<00:06,  3.04it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  97%|█████████▋| 559/579 [03:03<00:06,  3.04it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  97%|█████████▋| 560/579 [03:04<00:06,  3.04it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  97%|█████████▋| 561/579 [03:04<00:05,  3.04it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  97%|█████████▋| 562/579 [03:04<00:05,  3.05it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  97%|█████████▋| 563/579 [03:04<00:05,  3.05it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  97%|█████████▋| 564/579 [03:04<00:04,  3.05it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  98%|█████████▊| 565/579 [03:05<00:04,  3.05it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  98%|█████████▊| 566/579 [03:05<00:04,  3.05it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  98%|█████████▊| 567/579 [03:05<00:03,  3.05it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  98%|█████████▊| 568/579 [03:05<00:03,  3.06it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  98%|█████████▊| 569/579 [03:06<00:03,  3.06it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  98%|█████████▊| 570/579 [03:06<00:02,  3.06it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  99%|█████████▊| 571/579 [03:06<00:02,  3.06it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  99%|█████████▉| 572/579 [03:06<00:02,  3.06it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  99%|█████████▉| 573/579 [03:06<00:01,  3.07it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  99%|█████████▉| 574/579 [03:07<00:01,  3.07it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  99%|█████████▉| 575/579 [03:07<00:01,  3.07it/s, loss=3.116, v_num=6]\n",
      "Epoch 2:  99%|█████████▉| 576/579 [03:07<00:00,  3.07it/s, loss=3.116, v_num=6]\n",
      "Epoch 2: 100%|█████████▉| 577/579 [03:07<00:00,  3.07it/s, loss=3.116, v_num=6]\n",
      "Epoch 2: 100%|█████████▉| 578/579 [03:08<00:00,  3.07it/s, loss=3.116, v_num=6]\n",
      "Epoch 2: 100%|██████████| 579/579 [03:08<00:00,  3.08it/s, loss=3.116, v_num=6]Mean val Loss: 2.9762589931488037\n",
      "Epoch 2: 100%|██████████| 579/579 [03:08<00:00,  3.08it/s, loss=3.116, v_num=6]\n",
      "                                                           \u001b[AMean train Loss: 3.203159809112549\n",
      "Epoch 3:  91%|█████████ | 525/579 [03:02<00:18,  2.87it/s, loss=2.734, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 526/579 [03:03<00:18,  2.87it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  91%|█████████ | 527/579 [03:03<00:18,  2.88it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  91%|█████████ | 528/579 [03:03<00:17,  2.88it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  91%|█████████▏| 529/579 [03:03<00:17,  2.88it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  92%|█████████▏| 530/579 [03:03<00:17,  2.88it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  92%|█████████▏| 531/579 [03:04<00:16,  2.88it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  92%|█████████▏| 532/579 [03:04<00:16,  2.88it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  92%|█████████▏| 533/579 [03:04<00:15,  2.89it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  92%|█████████▏| 534/579 [03:04<00:15,  2.89it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  92%|█████████▏| 535/579 [03:05<00:15,  2.89it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  93%|█████████▎| 536/579 [03:05<00:14,  2.89it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  93%|█████████▎| 537/579 [03:05<00:14,  2.89it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  93%|█████████▎| 538/579 [03:05<00:14,  2.90it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  93%|█████████▎| 539/579 [03:06<00:13,  2.90it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  93%|█████████▎| 540/579 [03:06<00:13,  2.90it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  93%|█████████▎| 541/579 [03:06<00:13,  2.90it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  94%|█████████▎| 542/579 [03:06<00:12,  2.90it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  94%|█████████▍| 543/579 [03:06<00:12,  2.90it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  94%|█████████▍| 544/579 [03:07<00:12,  2.91it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  94%|█████████▍| 545/579 [03:07<00:11,  2.91it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  94%|█████████▍| 546/579 [03:07<00:11,  2.91it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  94%|█████████▍| 547/579 [03:07<00:10,  2.91it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  95%|█████████▍| 548/579 [03:08<00:10,  2.91it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  95%|█████████▍| 549/579 [03:08<00:10,  2.91it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  95%|█████████▍| 550/579 [03:08<00:09,  2.92it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  95%|█████████▌| 551/579 [03:08<00:09,  2.92it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  95%|█████████▌| 552/579 [03:09<00:09,  2.92it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  96%|█████████▌| 553/579 [03:09<00:08,  2.92it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  96%|█████████▌| 554/579 [03:09<00:08,  2.92it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  96%|█████████▌| 555/579 [03:09<00:08,  2.93it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  96%|█████████▌| 556/579 [03:09<00:07,  2.93it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  96%|█████████▌| 557/579 [03:10<00:07,  2.93it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  96%|█████████▋| 558/579 [03:10<00:07,  2.93it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  97%|█████████▋| 559/579 [03:10<00:06,  2.93it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  97%|█████████▋| 560/579 [03:10<00:06,  2.93it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  97%|█████████▋| 561/579 [03:11<00:06,  2.94it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  97%|█████████▋| 562/579 [03:11<00:05,  2.94it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  97%|█████████▋| 563/579 [03:11<00:05,  2.94it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  97%|█████████▋| 564/579 [03:11<00:05,  2.94it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  98%|█████████▊| 565/579 [03:12<00:04,  2.94it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  98%|█████████▊| 566/579 [03:12<00:04,  2.94it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  98%|█████████▊| 567/579 [03:12<00:04,  2.94it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  98%|█████████▊| 568/579 [03:12<00:03,  2.95it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  98%|█████████▊| 569/579 [03:13<00:03,  2.95it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  98%|█████████▊| 570/579 [03:13<00:03,  2.95it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  99%|█████████▊| 571/579 [03:13<00:02,  2.95it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  99%|█████████▉| 572/579 [03:13<00:02,  2.95it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  99%|█████████▉| 573/579 [03:13<00:02,  2.95it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  99%|█████████▉| 574/579 [03:14<00:01,  2.96it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  99%|█████████▉| 575/579 [03:14<00:01,  2.96it/s, loss=2.734, v_num=6]\n",
      "Epoch 3:  99%|█████████▉| 576/579 [03:14<00:01,  2.96it/s, loss=2.734, v_num=6]\n",
      "Epoch 3: 100%|█████████▉| 577/579 [03:14<00:00,  2.96it/s, loss=2.734, v_num=6]\n",
      "Epoch 3: 100%|█████████▉| 578/579 [03:15<00:00,  2.96it/s, loss=2.734, v_num=6]\n",
      "Epoch 3: 100%|██████████| 579/579 [03:15<00:00,  2.96it/s, loss=2.734, v_num=6]Mean val Loss: 2.858914613723755\n",
      "Epoch 3: 100%|██████████| 579/579 [03:15<00:00,  2.96it/s, loss=2.734, v_num=6]\n",
      "                                                           \u001b[AMean train Loss: 2.9317378997802734\n",
      "Epoch 4:  91%|█████████ | 525/579 [03:06<00:19,  2.81it/s, loss=2.761, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 526/579 [03:07<00:18,  2.81it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  91%|█████████ | 527/579 [03:07<00:18,  2.81it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  91%|█████████ | 528/579 [03:07<00:18,  2.81it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  91%|█████████▏| 529/579 [03:07<00:17,  2.82it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  92%|█████████▏| 530/579 [03:08<00:17,  2.82it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  92%|█████████▏| 531/579 [03:08<00:17,  2.82it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  92%|█████████▏| 532/579 [03:08<00:16,  2.82it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  92%|█████████▏| 533/579 [03:08<00:16,  2.82it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  92%|█████████▏| 534/579 [03:08<00:15,  2.83it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  92%|█████████▏| 535/579 [03:09<00:15,  2.83it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  93%|█████████▎| 536/579 [03:09<00:15,  2.83it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  93%|█████████▎| 537/579 [03:09<00:14,  2.83it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  93%|█████████▎| 538/579 [03:09<00:14,  2.83it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  93%|█████████▎| 539/579 [03:10<00:14,  2.83it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  93%|█████████▎| 540/579 [03:10<00:13,  2.84it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  93%|█████████▎| 541/579 [03:10<00:13,  2.84it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  94%|█████████▎| 542/579 [03:10<00:13,  2.84it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  94%|█████████▍| 543/579 [03:11<00:12,  2.84it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  94%|█████████▍| 544/579 [03:11<00:12,  2.84it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  94%|█████████▍| 545/579 [03:11<00:11,  2.85it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  94%|█████████▍| 546/579 [03:11<00:11,  2.85it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  94%|█████████▍| 547/579 [03:11<00:11,  2.85it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  95%|█████████▍| 548/579 [03:12<00:10,  2.85it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  95%|█████████▍| 549/579 [03:12<00:10,  2.85it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  95%|█████████▍| 550/579 [03:12<00:10,  2.85it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  95%|█████████▌| 551/579 [03:12<00:09,  2.86it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  95%|█████████▌| 552/579 [03:13<00:09,  2.86it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  96%|█████████▌| 553/579 [03:13<00:09,  2.86it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  96%|█████████▌| 554/579 [03:13<00:08,  2.86it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  96%|█████████▌| 555/579 [03:13<00:08,  2.86it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  96%|█████████▌| 556/579 [03:14<00:08,  2.86it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  96%|█████████▌| 557/579 [03:14<00:07,  2.87it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  96%|█████████▋| 558/579 [03:14<00:07,  2.87it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  97%|█████████▋| 559/579 [03:14<00:06,  2.87it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  97%|█████████▋| 560/579 [03:15<00:06,  2.87it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  97%|█████████▋| 561/579 [03:15<00:06,  2.87it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  97%|█████████▋| 562/579 [03:15<00:05,  2.87it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  97%|█████████▋| 563/579 [03:15<00:05,  2.88it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  97%|█████████▋| 564/579 [03:16<00:05,  2.88it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  98%|█████████▊| 565/579 [03:16<00:04,  2.88it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  98%|█████████▊| 566/579 [03:16<00:04,  2.88it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  98%|█████████▊| 567/579 [03:16<00:04,  2.88it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  98%|█████████▊| 568/579 [03:16<00:03,  2.88it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  98%|█████████▊| 569/579 [03:17<00:03,  2.89it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  98%|█████████▊| 570/579 [03:17<00:03,  2.89it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  99%|█████████▊| 571/579 [03:17<00:02,  2.89it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  99%|█████████▉| 572/579 [03:17<00:02,  2.89it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  99%|█████████▉| 573/579 [03:18<00:02,  2.89it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  99%|█████████▉| 574/579 [03:18<00:01,  2.89it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  99%|█████████▉| 575/579 [03:18<00:01,  2.89it/s, loss=2.761, v_num=6]\n",
      "Epoch 4:  99%|█████████▉| 576/579 [03:18<00:01,  2.90it/s, loss=2.761, v_num=6]\n",
      "Epoch 4: 100%|█████████▉| 577/579 [03:19<00:00,  2.90it/s, loss=2.761, v_num=6]\n",
      "Epoch 4: 100%|█████████▉| 578/579 [03:19<00:00,  2.90it/s, loss=2.761, v_num=6]\n",
      "Epoch 4: 100%|██████████| 579/579 [03:19<00:00,  2.90it/s, loss=2.761, v_num=6]Mean val Loss: 2.6444408893585205\n",
      "Epoch 4: 100%|██████████| 579/579 [03:19<00:00,  2.90it/s, loss=2.761, v_num=6]\n",
      "                                                           \u001b[AMean train Loss: 2.7731661796569824\n",
      "Epoch 5:  91%|█████████ | 525/579 [02:56<00:18,  2.97it/s, loss=2.688, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 526/579 [02:56<00:17,  2.97it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  91%|█████████ | 527/579 [02:57<00:17,  2.98it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  91%|█████████ | 528/579 [02:57<00:17,  2.98it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  91%|█████████▏| 529/579 [02:57<00:16,  2.98it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  92%|█████████▏| 530/579 [02:57<00:16,  2.98it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  92%|█████████▏| 531/579 [02:57<00:16,  2.99it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  92%|█████████▏| 532/579 [02:58<00:15,  2.99it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  92%|█████████▏| 533/579 [02:58<00:15,  2.99it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  92%|█████████▏| 534/579 [02:58<00:15,  2.99it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  92%|█████████▏| 535/579 [02:58<00:14,  2.99it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  93%|█████████▎| 536/579 [02:59<00:14,  2.99it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  93%|█████████▎| 537/579 [02:59<00:14,  3.00it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  93%|█████████▎| 538/579 [02:59<00:13,  3.00it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  93%|█████████▎| 539/579 [02:59<00:13,  3.00it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  93%|█████████▎| 540/579 [02:59<00:12,  3.00it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  93%|█████████▎| 541/579 [03:00<00:12,  3.00it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  94%|█████████▎| 542/579 [03:00<00:12,  3.01it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  94%|█████████▍| 543/579 [03:00<00:11,  3.01it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  94%|█████████▍| 544/579 [03:00<00:11,  3.01it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  94%|█████████▍| 545/579 [03:00<00:11,  3.01it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  94%|█████████▍| 546/579 [03:01<00:10,  3.02it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  94%|█████████▍| 547/579 [03:01<00:10,  3.02it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  95%|█████████▍| 548/579 [03:01<00:10,  3.02it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  95%|█████████▍| 549/579 [03:01<00:09,  3.02it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  95%|█████████▍| 550/579 [03:01<00:09,  3.02it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  95%|█████████▌| 551/579 [03:02<00:09,  3.02it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  95%|█████████▌| 552/579 [03:02<00:08,  3.03it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  96%|█████████▌| 553/579 [03:02<00:08,  3.03it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  96%|█████████▌| 554/579 [03:02<00:08,  3.03it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  96%|█████████▌| 555/579 [03:03<00:07,  3.03it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  96%|█████████▌| 556/579 [03:03<00:07,  3.03it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  96%|█████████▌| 557/579 [03:03<00:07,  3.04it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  96%|█████████▋| 558/579 [03:03<00:06,  3.04it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  97%|█████████▋| 559/579 [03:03<00:06,  3.04it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  97%|█████████▋| 560/579 [03:04<00:06,  3.04it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  97%|█████████▋| 561/579 [03:04<00:05,  3.04it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  97%|█████████▋| 562/579 [03:04<00:05,  3.05it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  97%|█████████▋| 563/579 [03:04<00:05,  3.05it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  97%|█████████▋| 564/579 [03:04<00:04,  3.05it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  98%|█████████▊| 565/579 [03:05<00:04,  3.05it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  98%|█████████▊| 566/579 [03:05<00:04,  3.05it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  98%|█████████▊| 567/579 [03:05<00:03,  3.06it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  98%|█████████▊| 568/579 [03:05<00:03,  3.06it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  98%|█████████▊| 569/579 [03:05<00:03,  3.06it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  98%|█████████▊| 570/579 [03:06<00:02,  3.06it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  99%|█████████▊| 571/579 [03:06<00:02,  3.06it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  99%|█████████▉| 572/579 [03:06<00:02,  3.07it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  99%|█████████▉| 573/579 [03:06<00:01,  3.07it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  99%|█████████▉| 574/579 [03:07<00:01,  3.07it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  99%|█████████▉| 575/579 [03:07<00:01,  3.07it/s, loss=2.688, v_num=6]\n",
      "Epoch 5:  99%|█████████▉| 576/579 [03:07<00:00,  3.07it/s, loss=2.688, v_num=6]\n",
      "Epoch 5: 100%|█████████▉| 577/579 [03:07<00:00,  3.08it/s, loss=2.688, v_num=6]\n",
      "Epoch 5: 100%|█████████▉| 578/579 [03:07<00:00,  3.08it/s, loss=2.688, v_num=6]\n",
      "Epoch 5: 100%|██████████| 579/579 [03:07<00:00,  3.08it/s, loss=2.688, v_num=6]Mean val Loss: 2.593194007873535\n",
      "Epoch 5: 100%|██████████| 579/579 [03:07<00:00,  3.08it/s, loss=2.688, v_num=6]\n",
      "                                                           \u001b[AMean train Loss: 2.6616322994232178\n",
      "Epoch 6:  91%|█████████ | 525/579 [03:04<00:18,  2.85it/s, loss=2.582, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 526/579 [03:04<00:18,  2.85it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  91%|█████████ | 527/579 [03:04<00:18,  2.85it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  91%|█████████ | 528/579 [03:04<00:17,  2.86it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  91%|█████████▏| 529/579 [03:05<00:17,  2.86it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  92%|█████████▏| 530/579 [03:05<00:17,  2.86it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  92%|█████████▏| 531/579 [03:05<00:16,  2.86it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  92%|█████████▏| 532/579 [03:05<00:16,  2.86it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  92%|█████████▏| 533/579 [03:05<00:16,  2.87it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  92%|█████████▏| 534/579 [03:06<00:15,  2.87it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  92%|█████████▏| 535/579 [03:06<00:15,  2.87it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  93%|█████████▎| 536/579 [03:06<00:14,  2.87it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  93%|█████████▎| 537/579 [03:06<00:14,  2.87it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  93%|█████████▎| 538/579 [03:07<00:14,  2.88it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  93%|█████████▎| 539/579 [03:07<00:13,  2.88it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  93%|█████████▎| 540/579 [03:07<00:13,  2.88it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  93%|█████████▎| 541/579 [03:07<00:13,  2.88it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  94%|█████████▎| 542/579 [03:08<00:12,  2.88it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  94%|█████████▍| 543/579 [03:08<00:12,  2.88it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  94%|█████████▍| 544/579 [03:08<00:12,  2.89it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  94%|█████████▍| 545/579 [03:08<00:11,  2.89it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  94%|█████████▍| 546/579 [03:08<00:11,  2.89it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  94%|█████████▍| 547/579 [03:09<00:11,  2.89it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  95%|█████████▍| 548/579 [03:09<00:10,  2.89it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  95%|█████████▍| 549/579 [03:09<00:10,  2.89it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  95%|█████████▍| 550/579 [03:09<00:10,  2.90it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  95%|█████████▌| 551/579 [03:10<00:09,  2.90it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  95%|█████████▌| 552/579 [03:10<00:09,  2.90it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  96%|█████████▌| 553/579 [03:10<00:08,  2.90it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  96%|█████████▌| 554/579 [03:10<00:08,  2.90it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  96%|█████████▌| 555/579 [03:11<00:08,  2.91it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  96%|█████████▌| 556/579 [03:11<00:07,  2.91it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  96%|█████████▌| 557/579 [03:11<00:07,  2.91it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  96%|█████████▋| 558/579 [03:11<00:07,  2.91it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  97%|█████████▋| 559/579 [03:11<00:06,  2.91it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  97%|█████████▋| 560/579 [03:12<00:06,  2.91it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  97%|█████████▋| 561/579 [03:12<00:06,  2.92it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  97%|█████████▋| 562/579 [03:12<00:05,  2.92it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  97%|█████████▋| 563/579 [03:12<00:05,  2.92it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  97%|█████████▋| 564/579 [03:13<00:05,  2.92it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  98%|█████████▊| 565/579 [03:13<00:04,  2.92it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  98%|█████████▊| 566/579 [03:13<00:04,  2.92it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  98%|█████████▊| 567/579 [03:13<00:04,  2.93it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  98%|█████████▊| 568/579 [03:14<00:03,  2.93it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  98%|█████████▊| 569/579 [03:14<00:03,  2.93it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  98%|█████████▊| 570/579 [03:14<00:03,  2.93it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  99%|█████████▊| 571/579 [03:14<00:02,  2.93it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  99%|█████████▉| 572/579 [03:14<00:02,  2.93it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  99%|█████████▉| 573/579 [03:15<00:02,  2.94it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  99%|█████████▉| 574/579 [03:15<00:01,  2.94it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  99%|█████████▉| 575/579 [03:15<00:01,  2.94it/s, loss=2.582, v_num=6]\n",
      "Epoch 6:  99%|█████████▉| 576/579 [03:15<00:01,  2.94it/s, loss=2.582, v_num=6]\n",
      "Epoch 6: 100%|█████████▉| 577/579 [03:16<00:00,  2.94it/s, loss=2.582, v_num=6]\n",
      "Epoch 6: 100%|█████████▉| 578/579 [03:16<00:00,  2.94it/s, loss=2.582, v_num=6]\n",
      "Epoch 6: 100%|██████████| 579/579 [03:16<00:00,  2.95it/s, loss=2.582, v_num=6]Mean val Loss: 2.441760778427124\n",
      "Epoch 6: 100%|██████████| 579/579 [03:16<00:00,  2.95it/s, loss=2.582, v_num=6]\n",
      "                                                           \u001b[AMean train Loss: 2.5792641639709473\n",
      "Epoch 7:  91%|█████████ | 525/579 [03:03<00:18,  2.85it/s, loss=2.595, v_num=6]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 526/579 [03:04<00:18,  2.86it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  91%|█████████ | 527/579 [03:04<00:18,  2.86it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  91%|█████████ | 528/579 [03:04<00:17,  2.86it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  91%|█████████▏| 529/579 [03:04<00:17,  2.86it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  92%|█████████▏| 530/579 [03:05<00:17,  2.86it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  92%|█████████▏| 531/579 [03:05<00:16,  2.87it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  92%|█████████▏| 532/579 [03:05<00:16,  2.87it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  92%|█████████▏| 533/579 [03:05<00:16,  2.87it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  92%|█████████▏| 534/579 [03:05<00:15,  2.87it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  92%|█████████▏| 535/579 [03:06<00:15,  2.87it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  93%|█████████▎| 536/579 [03:06<00:14,  2.88it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  93%|█████████▎| 537/579 [03:06<00:14,  2.88it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  93%|█████████▎| 538/579 [03:06<00:14,  2.88it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  93%|█████████▎| 539/579 [03:07<00:13,  2.88it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  93%|█████████▎| 540/579 [03:07<00:13,  2.88it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  93%|█████████▎| 541/579 [03:07<00:13,  2.89it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  94%|█████████▎| 542/579 [03:07<00:12,  2.89it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  94%|█████████▍| 543/579 [03:07<00:12,  2.89it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  94%|█████████▍| 544/579 [03:08<00:12,  2.89it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  94%|█████████▍| 545/579 [03:08<00:11,  2.89it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  94%|█████████▍| 546/579 [03:08<00:11,  2.89it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  94%|█████████▍| 547/579 [03:08<00:11,  2.90it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  95%|█████████▍| 548/579 [03:09<00:10,  2.90it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  95%|█████████▍| 549/579 [03:09<00:10,  2.90it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  95%|█████████▍| 550/579 [03:09<00:09,  2.90it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  95%|█████████▌| 551/579 [03:09<00:09,  2.90it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  95%|█████████▌| 552/579 [03:10<00:09,  2.90it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  96%|█████████▌| 553/579 [03:10<00:08,  2.91it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  96%|█████████▌| 554/579 [03:10<00:08,  2.91it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  96%|█████████▌| 555/579 [03:10<00:08,  2.91it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  96%|█████████▌| 556/579 [03:10<00:07,  2.91it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  96%|█████████▌| 557/579 [03:11<00:07,  2.91it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  96%|█████████▋| 558/579 [03:11<00:07,  2.92it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  97%|█████████▋| 559/579 [03:11<00:06,  2.92it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  97%|█████████▋| 560/579 [03:11<00:06,  2.92it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  97%|█████████▋| 561/579 [03:12<00:06,  2.92it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  97%|█████████▋| 562/579 [03:12<00:05,  2.92it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  97%|█████████▋| 563/579 [03:12<00:05,  2.92it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  97%|█████████▋| 564/579 [03:12<00:05,  2.93it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  98%|█████████▊| 565/579 [03:12<00:04,  2.93it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  98%|█████████▊| 566/579 [03:13<00:04,  2.93it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  98%|█████████▊| 567/579 [03:13<00:04,  2.93it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  98%|█████████▊| 568/579 [03:13<00:03,  2.93it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  98%|█████████▊| 569/579 [03:13<00:03,  2.94it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  98%|█████████▊| 570/579 [03:14<00:03,  2.94it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  99%|█████████▊| 571/579 [03:14<00:02,  2.94it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  99%|█████████▉| 572/579 [03:14<00:02,  2.94it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  99%|█████████▉| 573/579 [03:14<00:02,  2.94it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  99%|█████████▉| 574/579 [03:14<00:01,  2.94it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  99%|█████████▉| 575/579 [03:15<00:01,  2.95it/s, loss=2.595, v_num=6]\n",
      "Epoch 7:  99%|█████████▉| 576/579 [03:15<00:01,  2.95it/s, loss=2.595, v_num=6]\n",
      "Epoch 7: 100%|█████████▉| 577/579 [03:15<00:00,  2.95it/s, loss=2.595, v_num=6]\n",
      "Epoch 7: 100%|█████████▉| 578/579 [03:15<00:00,  2.95it/s, loss=2.595, v_num=6]\n",
      "Epoch 7: 100%|██████████| 579/579 [03:15<00:00,  2.95it/s, loss=2.595, v_num=6]Mean val Loss: 2.459808588027954\n",
      "Epoch 7: 100%|██████████| 579/579 [03:15<00:00,  2.95it/s, loss=2.595, v_num=6]\n",
      "                                                           \u001b[AMean train Loss: 2.516303539276123\n",
      "Epoch 7: 100%|██████████| 579/579 [03:31<00:00,  2.74it/s, loss=2.595, v_num=6]\n",
      "Testing: 100%|█████████▉| 346/347 [05:12<00:00,  1.14it/s]Mean test Loss: 2.6521682739257812\n",
      "{'testlen': 135295, 'reflen': 145417, 'guess': [135295, 123669, 113595, 106110], 'correct': [84113, 65310, 53714, 45821]}\n",
      "ratio: 0.9303932827661077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/Development/QuestionAnweringProject/MSMARCO-Question-Answering/MsmarcoQuestionAnswering/Evaluation/ms_marco_eval.py:167: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  answersimilarity += candidate_answer.similarity(nlp(answer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_loss': tensor(2.6522, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|█████████▉| 346/347 [08:19<00:01,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "modelLightning = BidafLightningWrapper()\n",
    "#-------Early Stopping-------\n",
    "early_stopping = EarlyStopping('val_loss', patience=0)\n",
    "trainer = Trainer(gpus=1, early_stop_callback=early_stopping)\n",
    "trainer.fit(modelLightning)\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Checkpoint and resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "modelLightning = BidafLightningWrapper()\n",
    "early_stopping = EarlyStopping('val_loss')\n",
    "trainer = Trainer(early_stop_callback=early_stopping, gpus=1, resume_from_checkpoint= os.path.join(args.exp_folder,\"checkpoint.ckpt\"))\n",
    "trainer.fit(modelLightning)\n",
    "#trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Pytorch Lightning Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(os.path.join(args.exp_folder,\"checkpoint.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Loss to statistics.json (to be executed directly after training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "outputfile = os.path.join(args.exp_folder,'statistics.json')\n",
    "Path(outputfile).touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeStatisticToDict(key, output_dict, start_epoch = 0):\n",
    "    output_dict[key] = dict()\n",
    "    stat_saves = epoch_saves[key]\n",
    "\n",
    "    for idx in range(0 + start_epoch,len(stat_saves)+start_epoch):\n",
    "        output_dict[key][idx] = dict()\n",
    "        for jdx in range(0,len(stat_saves[idx])):\n",
    "            output_dict[key][idx][jdx] = stat_saves[idx][jdx].item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = dict()\n",
    "\n",
    "writeStatisticToDict('train_loss',output_dict)\n",
    "writeStatisticToDict('val_loss',output_dict)\n",
    "writeStatisticToDict('test_loss',output_dict)\n",
    "\n",
    "with open(outputfile, 'w') as write_f:\n",
    "    write_f.write(json.dumps(output_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Loss from statistics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "outputfile = os.path.join(args.exp_folder,'statistics.json')\n",
    "with open(outputfile, 'r') as read_f:\n",
    "    statistics = json.load(read_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot per Epoch Mean Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visualizeEpochMeanLoss(key, stats, skip_first=False, plot_variance=True, color = None, label = None):\n",
    "    \n",
    "    if not label:\n",
    "        label = key\n",
    "    \n",
    "    epoch_stats_dict = stats[key]\n",
    "    mean_loss = []\n",
    "    var_loss = []\n",
    "    first = True\n",
    "    for epochNum in epoch_stats_dict:\n",
    "        if first and skip_first:\n",
    "            first = False\n",
    "            continue\n",
    "        epoch_stats = epoch_stats_dict[epochNum].values()\n",
    "        epoch_stats = np.array(list(epoch_stats))\n",
    "        mean_loss_in_actual_epoch = np.average(epoch_stats)\n",
    "        mean_loss = mean_loss + [mean_loss_in_actual_epoch]\n",
    "        variance_loss_in_actual_epoch = np.var(epoch_stats)\n",
    "        var_loss = var_loss + [variance_loss_in_actual_epoch]\n",
    "    \n",
    "    x = np.arange(0,len(epoch_stats_dict.keys()) - skip_first)\n",
    "    if plot_variance:\n",
    "        plt.errorbar(x, mean_loss, yerr=var_loss, label = label)\n",
    "    else:\n",
    "        if color:\n",
    "            plt.plot(x,mean_loss, label = label, color = color)\n",
    "        else:    \n",
    "            plt.plot(x,mean_loss, label = label)\n",
    "    \n",
    "def visualizeTestMeanLoss(train_key, test_key, stats):\n",
    "    epoch_stats_dict = stats[test_key]\n",
    "    mean_loss = []\n",
    "    epoch_stats = epoch_stats_dict['0'].values()\n",
    "    mean_loss_in_actual_epoch = sum(epoch_stats)/len(epoch_stats)\n",
    "    for epochs in stats[train_key]:\n",
    "        mean_loss = mean_loss + [mean_loss_in_actual_epoch]\n",
    "    plt.plot(mean_loss, label = test_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizeEpochMeanLoss('train_loss', statistics)\n",
    "visualizeEpochMeanLoss('val_loss',statistics, skip_first=True)\n",
    "visualizeTestMeanLoss('train_loss','test_loss',statistics)\n",
    "plt.legend(loc='upper right', frameon=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(2,5)\n",
    "plt.savefig(os.path.join(args.exp_folder, 'loss.png'))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot per Batch Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def visualizeLoss(key, stats):\n",
    "    batch_stats = stats[key]\n",
    "    epoch_stats = []\n",
    "    for key in batch_stats:\n",
    "        epoch_stats = epoch_stats + list(batch_stats[key].values())\n",
    "    plt.plot(epoch_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeLoss('train_loss', statistics)\n",
    "visualizeLoss('val_loss',statistics)\n",
    "visualizeLoss('test_loss',statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Multiple Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for i in range(1,7,1):\n",
    "    path= os.path.join(pwd, 'Experimente/LearnCurve_0' + str(i),'statistics.json')\n",
    "    with open(path, 'r') as read_f:\n",
    "        statistics = json.load(read_f)\n",
    "    visualizeEpochMeanLoss('val_loss',statistics, skip_first=True,plot_variance=False, color = (0,0,(i)/8,(i)/8), label = '0.' + str(i))\n",
    "    \n",
    "path = os.path.join(pwd, 'Experimente/EarlyStoppingAdam', 'statistics.json')\n",
    "with open(path, 'r') as read_f:\n",
    "    statistics = json.load(read_f)\n",
    "visualizeEpochMeanLoss('val_loss',statistics, skip_first=True,plot_variance=False, color = (0,0,8/8,(8)/8), label = '1' )\n",
    "\n",
    "plt.legend(loc='upper right', frameon=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(2,3.5)\n",
    "plt.savefig(os.path.join(pwd, 'multiple_vals_1.png'))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Learn Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def getLastMeanVar(key, stats):\n",
    "    epoch_stats_dict = stats[key]\n",
    "    first = True\n",
    "    epochNum = list(epoch_stats_dict.keys()).pop()\n",
    "    epoch_stats = epoch_stats_dict[epochNum].values()\n",
    "    epoch_stats = np.array(list(epoch_stats))\n",
    "    mean_loss_in_actual_epoch = np.average(epoch_stats)\n",
    "    variance_loss_in_actual_epoch = np.var(epoch_stats)\n",
    "    return (mean_loss_in_actual_epoch,variance_loss_in_actual_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotLastMeanVar(key):\n",
    "    mean_loss = []\n",
    "    var_loss = []\n",
    "    x = []\n",
    "    for i in range(1,7,1):\n",
    "        path= os.path.join(pwd, 'Experimente/LearnCurve_0' + str(i),'statistics.json')\n",
    "        with open(path, 'r') as read_f:\n",
    "            statistics = json.load(read_f)\n",
    "        mean,var = getLastMeanVar(key,statistics)\n",
    "        mean_loss = mean_loss + [mean]\n",
    "        var_loss = var_loss + [var]  \n",
    "        x = x + ['0.'+str(i)]\n",
    "    path = os.path.join(pwd, 'Experimente/EarlyStoppingAdam', 'statistics.json')\n",
    "    with open(path, 'r') as read_f:\n",
    "        statistics = json.load(read_f)\n",
    "    mean,var = getLastMeanVar('val_loss',statistics)\n",
    "    mean_loss = mean_loss + [mean]\n",
    "    var_loss = var_loss + [var]\n",
    "    x = x + ['1']\n",
    "\n",
    "    plt.errorbar(x, mean_loss, yerr=var_loss, label = key)\n",
    "\n",
    "plotLastMeanVar('val_loss')\n",
    "plotLastMeanVar('train_loss')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right', frameon=True)\n",
    "plt.xlabel(\"Dataset Size\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0,3.5)\n",
    "plt.savefig(os.path.join(pwd, 'learncurve.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
