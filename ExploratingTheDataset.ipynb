{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Raw JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "pwd = os.getcwd()\n",
    "\n",
    "class Arguments():\n",
    "    data = os.path.join(pwd, 'DATA', 'eval_v2.1_public.json')\n",
    "    exp_folder = os.path.join(pwd, 'Experimente/LightningTest')\n",
    "    word_rep = os.path.join(pwd, 'DATA', 'glove.840B.300d.txt')\n",
    "    cuda = torch.cuda.is_available()\n",
    "    use_covariance = False\n",
    "    force_restart = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "if not os.path.exists(args.exp_folder):\n",
    "    os.makedirs(args.exp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101092"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(args.data) as f_o:\n",
    "    file = json.load(f_o)\n",
    "    \n",
    "#file.keys()\n",
    "#file['answers'] #is a dict with qid --> ['Here is one long Answer with multiple Sentence in one String']\n",
    "#file['passages'] #is a dict with qid --> [{'is_selected': ..., 'passage_text':..., 'url':...},]\n",
    "#file['query'] #is a dict with qid --> 'Answer Sentence'\n",
    "#file['query_id'] #is a dict with qid --> Query ID\n",
    "#file['query_type'] #is a dict with qid --> Type of Query {'DESCRIPTION', 'NUMERIC', 'LOCATION',....}\n",
    "#file['wellFormedAnswers'] #is a dict with qid --> Well formulated Answers in form ['Here is a short well formulated Answer in one String']\n",
    "\n",
    "len(file['query_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['passages', 'query', 'query_id', 'query_type'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Loaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(pwd,'MsmarcoQuestionAnswering','Baseline'))\n",
    "sys.path.append(os.path.join(pwd,'MsmarcoQuestionAnswering','Baseline','scripts'))\n",
    "\n",
    "import MsmarcoQuestionAnswering.Baseline.mrcqa as mrcqa\n",
    "import MsmarcoQuestionAnswering.Baseline.scripts.dataset as dataset\n",
    "import MsmarcoQuestionAnswering.Baseline.scripts.checkpointing as checkpointing\n",
    "import MsmarcoQuestionAnswering.Baseline.scripts.train as manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Organizing Data...\n",
      "Organizing progress: 0.0 x 10⁴\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(args.data) as f_o:\n",
    "        data, _ = dataset.load_data(json.load(f_o), span_only=True, answered_only=True, loading_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 x 10⁴/0.0347 x 10⁴\n"
     ]
    }
   ],
   "source": [
    "#data is a List of validated and pre-processed Tuples with (qid, passage, query, (start_pos, end_pos))\n",
    "class DataIndizes():\n",
    "    qid = 0\n",
    "    passage = 1\n",
    "    query = 2\n",
    "    span = 3\n",
    "\n",
    "token_to_id = {'': 0}\n",
    "char_to_id = {'': 0}\n",
    "tokenized_data = dataset.tokenize_data(data, token_to_id, char_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restorative justice that fosters dialogue between victim and offender has shown the highest rates of victim satisfaction and offender accountability.\n",
      "['Restorative', 'justice', 'that', 'fosters', 'dialogue', 'between', 'victim', 'and', 'offender', 'has', 'shown', 'the', 'highest', 'rates', 'of', 'victim', 'satisfaction', 'and', 'offender', 'accountability', '.']\n"
     ]
    }
   ],
   "source": [
    "#tokenized_data is a tokenized form of the data before: A List of Tuples with (qid,passage,query,(start_pos_indizes, end_pos_indizes),token_to_char index mapping)\n",
    "#Where passage and query has the form: ([passage_tokens],[[char_tokens_per_word],...,])\n",
    "class TokenizedDataIndizes():\n",
    "    qid = 0\n",
    "    passage = 1\n",
    "    query = 2\n",
    "    span = 3\n",
    "    mapping = 4\n",
    "\n",
    "QID = 0\n",
    "\n",
    "#Create Inverse Dictionaries\n",
    "id_to_token = {id_: tok for tok, id_ in token_to_id.items()}\n",
    "id_to_char = {id_: char for char, id_ in char_to_id.items()}\n",
    "\n",
    "\n",
    "#Get the Answer to the question in not tokenized Data\n",
    "span = data[QID][DataIndizes.span]\n",
    "print(data[QID][DataIndizes.passage]['passage_text'][span[0]:span[1]])\n",
    "\n",
    "#Get the Answer to the question in tokenized Data\n",
    "span = tokenized_data[QID][TokenizedDataIndizes.span]\n",
    "passage_tokens = tokenized_data[QID][TokenizedDataIndizes.passage][0]\n",
    "print([id_to_token[tok] for tok in passage_tokens[span[0]:span[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Depona Ab is a library in Vilhelmina, Sweden.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from itertools import compress\n",
    "\n",
    "def qid_to_index(data, qid):\n",
    "    df = pandas.DataFrame(data)\n",
    "    boolean_pos = (df[0] == str(qid))\n",
    "    return list(compress(range(len(boolean_pos)), boolean_pos))\n",
    "\n",
    "def get_span(data,index):\n",
    "    return data[index][3]\n",
    "\n",
    "def get_passage_text(data,index):\n",
    "    return data[index][1]['passage_text']\n",
    "\n",
    "def span_to_answer(span,passage_text):\n",
    "    return passage_text[span[0]:span[1]]\n",
    "\n",
    "\n",
    "df = pandas.DataFrame(data)\n",
    "\n",
    "idx = qid_to_index(data,1000)[0]\n",
    "span_to_answer(get_span(data, idx),get_passage_text(data,idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
